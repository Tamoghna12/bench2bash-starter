# bench2bash-starter Snakemake Pipeline
# A modular, reproducible bioinformatics workflow

import pandas as pd
from pathlib import Path

# Load configuration
configfile: "config/config.yaml"

# Load sample metadata
samples_df = pd.read_csv(config["samples_file"], sep="\t")
SAMPLES = samples_df["sample_id"].tolist()

# Define output directories
RESULTS_DIR = Path(config["output_dir"])
LOGS_DIR = Path(config["logs_dir"])

# Ensure directories exist
RESULTS_DIR.mkdir(exist_ok=True)
LOGS_DIR.mkdir(exist_ok=True)

# All target rule - define final outputs
rule all:
    input:
        # Quality control outputs
        expand("results/qc/fastqc/{sample}_fastqc.html", sample=SAMPLES),
        "results/qc/multiqc_report.html",
        
        # Preprocessing outputs
        expand("results/trimmed/{sample}_trimmed_R1.fastq.gz", sample=SAMPLES),
        expand("results/trimmed/{sample}_trimmed_R2.fastq.gz", sample=SAMPLES),
        
        # Alignment outputs
        expand("results/aligned/{sample}.sorted.bam", sample=SAMPLES),
        
        # Analysis summary
        "results/analysis/summary_stats.txt"

# Quality control with FastQC
rule fastqc:
    input:
        fastq="data/samples/{sample}_R1.fastq.gz"
    output:
        html="results/qc/fastqc/{sample}_fastqc.html",
        zip="results/qc/fastqc/{sample}_fastqc.zip"
    params:
        outdir="results/qc/fastqc"
    threads: config["fastqc"]["threads"]
    log:
        "logs/fastqc/{sample}.log"
    conda:
        "envs/qc.yaml"
    shell:
        """
        mkdir -p {params.outdir}
        fastqc {input.fastq} -o {params.outdir} -t {threads} 2> {log}
        """

# Aggregate quality control with MultiQC
rule multiqc:
    input:
        expand("results/qc/fastqc/{sample}_fastqc.zip", sample=SAMPLES)
    output:
        "results/qc/multiqc_report.html"
    params:
        indir="results/qc/fastqc",
        outdir="results/qc"
    log:
        "logs/multiqc.log"
    conda:
        "envs/qc.yaml"
    shell:
        """
        multiqc {params.indir} -o {params.outdir} 2> {log}
        """

# Trim adapters and low-quality bases
rule trim_adapters:
    input:
        r1="data/samples/{sample}_R1.fastq.gz",
        r2="data/samples/{sample}_R2.fastq.gz"
    output:
        r1="results/trimmed/{sample}_trimmed_R1.fastq.gz",
        r2="results/trimmed/{sample}_trimmed_R2.fastq.gz",
        r1_unpaired="results/trimmed/{sample}_unpaired_R1.fastq.gz",
        r2_unpaired="results/trimmed/{sample}_unpaired_R2.fastq.gz"
    params:
        adapter_file=config["trimming"]["adapter_file"],
        quality_threshold=config["trimming"]["quality_threshold"],
        min_length=config["trimming"]["min_length"]
    threads: config["threads"]
    log:
        "logs/trimming/{sample}.log"
    conda:
        "envs/preprocessing.yaml"
    shell:
        """
        trimmomatic PE -threads {threads} \
            {input.r1} {input.r2} \
            {output.r1} {output.r1_unpaired} \
            {output.r2} {output.r2_unpaired} \
            ILLUMINACLIP:{params.adapter_file}:2:30:10 \
            LEADING:3 TRAILING:3 \
            SLIDINGWINDOW:4:{params.quality_threshold} \
            MINLEN:{params.min_length} 2> {log}
        """

# Align reads with STAR
rule align_reads:
    input:
        r1="results/trimmed/{sample}_trimmed_R1.fastq.gz",
        r2="results/trimmed/{sample}_trimmed_R2.fastq.gz"
    output:
        bam="results/aligned/{sample}.sorted.bam",
        log="results/aligned/{sample}.Log.final.out"
    params:
        index=config["alignment"]["index_dir"],
        prefix="results/aligned/{sample}."
    threads: config["alignment"]["threads"]
    log:
        "logs/alignment/{sample}.log"
    conda:
        "envs/alignment.yaml"
    shell:
        """
        STAR --genomeDir {params.index} \
             --readFilesIn {input.r1} {input.r2} \
             --readFilesCommand zcat \
             --runThreadN {threads} \
             --outFileNamePrefix {params.prefix} \
             --outSAMtype BAM SortedByCoordinate \
             --outSAMstrandField intronMotif 2> {log}
        
        # Rename output file
        mv {params.prefix}Aligned.sortedByCoord.out.bam {output.bam}
        """

# Index BAM files
rule index_bam:
    input:
        "results/aligned/{sample}.sorted.bam"
    output:
        "results/aligned/{sample}.sorted.bam.bai"
    conda:
        "envs/alignment.yaml"
    log:
        "logs/indexing/{sample}.log"
    shell:
        "samtools index {input} 2> {log}"

# Generate summary statistics
rule summary_stats:
    input:
        bams=expand("results/aligned/{sample}.sorted.bam", sample=SAMPLES),
        indices=expand("results/aligned/{sample}.sorted.bam.bai", sample=SAMPLES)
    output:
        "results/analysis/summary_stats.txt"
    log:
        "logs/analysis/summary_stats.log"
    conda:
        "envs/analysis.yaml"
    shell:
        """
        echo "Sample\tTotal_Reads\tMapped_Reads\tMapping_Rate" > {output}
        for bam in {input.bams}; do
            sample=$(basename $bam .sorted.bam)
            total=$(samtools view -c $bam)
            mapped=$(samtools view -c -F 4 $bam)
            rate=$(echo "scale=2; $mapped/$total*100" | bc)
            echo "$sample\t$total\t$mapped\t$rate%" >> {output}
        done 2> {log}
        """

# Clean up temporary files
rule clean:
    shell:
        """
        rm -rf temp/
        rm -rf results/trimmed/*_unpaired_*.fastq.gz
        echo "Cleanup complete"
        """